{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _config\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from utils.data_utils import get_libsvm_data, get_fit_dataloaders\n",
    "from torch.autograd import Variable\n",
    "from collections import Counter\n",
    "from modules.np_modules import construct_np_model, train_np_model, eval_np_model\n",
    "from utils.modules_utils import cal_fx, cal_km\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "from modules.conv_modules import Basic_Block, CNN_Res18\n",
    "from modules.data_modules import GeneralDataModule\n",
    "from modules.lightning_modules import CompressionNet"
   ]
  },
  {
   "source": [
    "## v1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = _config.datasets\n",
    "n_classes = _config.n_classes\n",
    "labels = _config.labels\n",
    "\n",
    "n_epoch = 1\n",
    "model_type = 'svc'\n",
    "kernel = 'rbf'\n",
    "traverse_list = ['a9a']\n",
    "\n",
    "map_size = 128\n",
    "blocks = [2,2,2,2]\n",
    "rate_list = [0.5]\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    min_delta=0.00,\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode='max'\n",
    ")\n"
   ]
  },
  {
   "source": [
    "### multiple dataset and compressed_rate run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...Load data\n",
      "Loading Finish: Time used 0.32\n",
      "---Dataset Info---\n",
      "dataset name:a9a\n",
      "n_features:123\n",
      "is_multi:False\n",
      "Trainset:[(0, 24720), (1, 7841)]\n",
      "Testset:[(0, 12435), (1, 3846)]\n",
      "\n",
      "... Train np model\n",
      "Training Finish: Time used 2.29\n",
      "dataset   \tacc       \tprecision \trecall    \tf1-score  \n",
      "trainset  \t0.86      \t0.82      \t0.78      \t0.80      \n",
      "testset   \t0.85      \t0.80      \t0.76      \t0.78      \n",
      "\n",
      "fx-realize:\n",
      "[-1.65739295 -1.10803564 -0.27469856  0.64455147 -2.14699336 -1.51682963\n",
      " -1.84686507  1.06113959 -1.8236303  -1.76943493]\n",
      "\n",
      "decision_function:\n",
      "[-1.65739295 -1.10803564 -0.27469856  0.64455147 -2.14699336 -1.51682963\n",
      " -1.84686507  1.06113959 -1.8236303  -1.76943493]\n",
      "\n",
      "y_pred\n",
      "[0 0 0 1 0 0 0 1 0 0]\n",
      "\n",
      "...Pre-processing\n",
      "----label 0----\n",
      "before X_temp_shape: (6118, 123)\n",
      "before coef_temp_shape: (6118, 1)\n",
      "after X_temp_shape: (6016, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 47.0\n",
      "47 map for each 128 item,total 6016\n",
      "batch X_temp_shape: (47, 1, 128, 123)\n",
      "batch coef_temp_shape: (47, 128, 1)\n",
      "----label 1----\n",
      "before X_temp_shape: (5632, 123)\n",
      "before coef_temp_shape: (5632, 1)\n",
      "after X_temp_shape: (5632, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 44.0\n",
      "44 map for each 128 item,total 5632\n",
      "batch X_temp_shape: (44, 1, 128, 123)\n",
      "batch coef_temp_shape: (44, 128, 1)\n",
      "\n",
      "data distribution compare:\n",
      "train data - num:32561, distribution:[(0, 24720), (1, 7841)]\n",
      "fit data - num:11750, distribution:[(0, 6118), (1, 5632)]\n",
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type      | Params\n",
      "-----------------------------------\n",
      "0 | conv | CNN_Res18 | 175 K \n",
      "-----------------------------------\n",
      "175 K     Trainable params\n",
      "0         Non-trainable params\n",
      "175 K     Total params\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27e80e48107b4e68a7cb5043539ed1dd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f2b7285a0174596882683bce93568ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nInitial coef:\nParameter containing:\ntensor([[0.8011, 0.1955, 0.4238, 0.4703, 0.8537, 0.1960, 0.1115, 0.6037, 0.6715,\n         0.0967, 0.4637, 0.6877, 0.1777, 0.7446, 0.8466, 0.1319, 0.3728, 0.5427,\n         0.2927, 0.0385, 0.0735, 0.8824, 0.2576, 0.1506, 0.2248, 0.2610, 0.4486,\n         0.1687, 0.9684, 0.3092, 0.2124, 0.7941, 0.1552, 0.7067, 0.8772, 0.7818,\n         0.1390, 0.2239, 0.4006, 0.6768, 0.8969, 0.5103, 0.8686, 0.6256, 0.4053,\n         0.5924, 0.7168, 0.0559, 0.2073, 0.1755, 0.1079, 0.5327, 0.0603, 0.4983,\n         0.7293, 0.6380, 0.3833, 0.1050, 0.8296, 0.5074, 0.4770, 0.5528, 0.8719,\n         0.3243]], requires_grad=True)\n\nInitial alpha_i:\ntensor([[0.8201, 0.1689, 0.4143, 0.4643, 0.8766, 0.1694, 0.0786, 0.6078, 0.6807,\n         0.0626, 0.4573, 0.6981, 0.1497, 0.7594, 0.8690, 0.1004, 0.3595, 0.5422,\n         0.2734, 0.0000, 0.0376, 0.9075, 0.2356, 0.1205, 0.2003, 0.2393, 0.4410,\n         0.1400, 1.0000, 0.2911, 0.1870, 0.8125, 0.1255, 0.7186, 0.9019, 0.7993,\n         0.1081, 0.1994, 0.3894, 0.6864, 0.9231, 0.5074, 0.8927, 0.6313, 0.3945,\n         0.5957, 0.7294, 0.0187, 0.1816, 0.1473, 0.0746, 0.5315, 0.0234, 0.4944,\n         0.7428, 0.6447, 0.3708, 0.0715, 0.8507, 0.5042, 0.4715, 0.5530, 0.8962,\n         0.3074]], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09fc85dc1d1f4186b1700e1bd4d1842d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nAfter train coef:\nParameter containing:\ntensor([[3.8007e+00, 3.9415e+00, 3.8692e+00, 3.5774e+00, 4.0650e+00, 3.6349e+00,\n         3.8539e+00, 3.5034e+00, 3.8113e+00, 3.9343e+00, 4.0723e+00, 3.9303e+00,\n         3.8368e+00, 3.8517e+00, 3.9371e+00, 3.8758e+00, 3.8756e+00, 3.5968e+00,\n         3.8454e+00, 1.3174e-03, 3.8310e+00, 3.5387e+00, 3.8535e+00, 3.6668e+00,\n         3.6205e+00, 3.7672e+00, 3.5820e+00, 3.5666e+00, 3.6564e+00, 3.8730e+00,\n         3.5803e+00, 3.7363e+00, 3.9408e+00, 3.9322e+00, 3.8389e+00, 3.8242e+00,\n         3.6309e+00, 3.5702e+00, 3.6029e+00, 4.0757e+00, 3.7160e+00, 4.0748e+00,\n         4.0689e+00, 3.6583e+00, 4.0024e+00, 3.6910e+00, 3.8725e+00, 3.7897e+00,\n         3.7737e+00, 3.6344e+00, 3.8350e+00, 3.9674e+00, 3.7322e+00, 3.8887e+00,\n         3.8193e+00, 3.8533e+00, 4.0740e+00, 4.0537e+00, 4.0655e+00, 3.7842e+00,\n         3.8802e+00, 3.4346e+00, 3.9988e+00, 3.6209e+00]], requires_grad=True)\n\nAfter train alpha_i:\ntensor([[0.9325, 0.9671, 0.9493, 0.8777, 0.9974, 0.8918, 0.9456, 0.8595, 0.9351,\n         0.9653, 0.9992, 0.9643, 0.9414, 0.9450, 0.9660, 0.9509, 0.9509, 0.8825,\n         0.9435, 0.0000, 0.9399, 0.8682, 0.9455, 0.8996, 0.8883, 0.9243, 0.8788,\n         0.8750, 0.8971, 0.9503, 0.8784, 0.9167, 0.9669, 0.9648, 0.9419, 0.9383,\n         0.8908, 0.8759, 0.8839, 1.0000, 0.9117, 0.9998, 0.9983, 0.8976, 0.9820,\n         0.9056, 0.9501, 0.9298, 0.9259, 0.8917, 0.9409, 0.9734, 0.9157, 0.9541,\n         0.9371, 0.9454, 0.9996, 0.9946, 0.9975, 0.9285, 0.9520, 0.8427, 0.9811,\n         0.8884]], grad_fn=<DivBackward0>)\n\n loss grads:\ntensor(1.)\n\n fx_hat grads:\ntensor([0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n        0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n        0.0278, 0.0278, 0.0278, 0.0015, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n        0.0278, 0.0278, 0.0272, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278])\n\n coef grads:\ntensor([[0.4663, 0.4666, 0.4661, 0.3119, 0.4664, 0.4664, 0.4663, 0.3119, 0.4662,\n         0.4667, 0.4665, 0.3119, 0.4665, 0.4663, 0.4663, 0.4664, 0.4665, 0.4665,\n         0.4666, 0.1835, 0.4667, 0.3119, 0.4663, 0.4664, 0.4668, 0.3119, 0.4663,\n         0.4665, 0.4664, 0.4661, 0.4666, 0.4665, 0.3119, 0.4662, 0.4662, 0.4665,\n         0.3119, 0.4666, 0.3119, 0.4661, 0.4664, 0.4665, 0.4665, 0.4664, 0.4662,\n         0.4664, 0.4665, 0.4663, 0.4661, 0.4666, 0.4664, 0.4664, 0.3119, 0.4665,\n         0.4661, 0.4662, 0.4665, 0.4663, 0.4664, 0.4663, 0.4664, 0.3119, 0.4664,\n         0.4665]])\n\n constrainted_alpha_i grads:\ntensor([[-0.4663, -0.4666, -0.4661, -0.3119, -0.4664, -0.4664, -0.4663, -0.3119,\n         -0.4662, -0.4667, -0.4665, -0.3119, -0.4665, -0.4663, -0.4663, -0.4664,\n         -0.4665, -0.4665, -0.4666, -0.1835, -0.4667, -0.3119, -0.4663, -0.4664,\n         -0.4668, -0.3119, -0.4663, -0.4665, -0.4664, -0.4661, -0.4666, -0.4665,\n         -0.3119, -0.4662, -0.4662, -0.4665, -0.3119, -0.4666, -0.3119, -0.4661,\n         -0.4664, -0.4665, -0.4665, -0.4664, -0.4662, -0.4664, -0.4665, -0.4663,\n         -0.4661, -0.4666, -0.4664, -0.4664, -0.3119, -0.4665, -0.4661, -0.4662,\n         -0.4665, -0.4663, -0.4664, -0.4663, -0.4664, -0.3119, -0.4664, -0.4665]])\n\n alpha_i grads:\ntensor([[-0.1148, -0.1148, -0.1147, -0.0768, -0.1148, -0.1148, -0.1148, -0.0768,\n         -0.1147, -0.1149, -0.1148, -0.0768, -0.1148, -0.1148, -0.1148, -0.1148,\n         -0.1148, -0.1148, -0.1148,  0.4237, -0.1149, -0.0768, -0.1148, -0.1148,\n         -0.1149, -0.0768, -0.1148, -0.1148, -0.1148, -0.1147, -0.1148, -0.1148,\n         -0.0768, -0.1147, -0.1147, -0.1148, -0.0768, -0.1148, -0.0768, -0.1147,\n         -0.1148, -0.1148, -0.1148, -0.1148, -0.1147, -0.1148, -0.1148, -0.1148,\n         -0.1147, -0.1148, -0.1148, -0.1148, -0.0768, -0.1148, -0.1147, -0.1147,\n         -0.1148, -0.1148, -0.1148, -0.1148, -0.1148, -0.0768,  6.3132, -0.1148]])\n\n km grads:\ntensor([[-0.0259, -0.0259, -0.0259,  ..., -0.0259, -0.0259, -0.0259],\n        [-0.0268, -0.0268, -0.0268,  ..., -0.0268, -0.0268, -0.0268],\n        [-0.0264, -0.0264, -0.0264,  ..., -0.0264, -0.0264, -0.0264],\n        ...,\n        [-0.0235, -0.0235, -0.0235,  ..., -0.0235, -0.0235, -0.0235],\n        [-0.0278, -0.0278, -0.0278,  ..., -0.0278, -0.0278, -0.0278],\n        [-0.0247, -0.0247, -0.0247,  ..., -0.0247, -0.0247, -0.0247]])\n\n X_compressed grads:\ntensor([[-6.6307e-03,  1.4329e-03,  1.5493e-03,  ...,  0.0000e+00,\n          0.0000e+00,  0.0000e+00],\n        [-6.1991e-03,  2.1533e-03,  2.2352e-03,  ...,  0.0000e+00,\n          0.0000e+00,  0.0000e+00],\n        [-6.5154e-03,  1.7007e-03,  1.7858e-03,  ...,  0.0000e+00,\n          0.0000e+00,  0.0000e+00],\n        ...,\n        [-1.2290e-02, -7.3489e-03, -7.3489e-03,  ...,  0.0000e+00,\n          0.0000e+00,  0.0000e+00],\n        [-6.0208e-03,  2.6353e-03,  2.7239e-03,  ...,  0.0000e+00,\n          8.9061e-05,  8.9061e-05],\n        [-5.5471e-03,  2.1299e-03,  2.2380e-03,  ...,  0.0000e+00,\n          0.0000e+00,  0.0000e+00]])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7ed188008b142c2a5043052bcf1cae0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(13.6322),\n",
      " 'test_mae': tensor(14.1322),\n",
      " 'test_mse': tensor(244.0771),\n",
      " 'test_var': tensor(0.2090),\n",
      " 'val_loss': tensor(12.0541),\n",
      " 'val_mae': tensor(12.5532),\n",
      " 'val_mse': tensor(196.8891),\n",
      " 'val_var': tensor(0.2024)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " eval compressed ins\n",
      "\n",
      "The 0-th ins:\n",
      "fx_compressed:[-25.24531806]\n",
      "fx_np_model:[-1.65739295]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 1-th ins:\n",
      "fx_compressed:[-28.89513162]\n",
      "fx_np_model:[-1.10803564]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 2-th ins:\n",
      "fx_compressed:[-25.47295713]\n",
      "fx_np_model:[-0.27469856]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 3-th ins:\n",
      "fx_compressed:[-24.9814386]\n",
      "fx_np_model:[0.64455147]\n",
      "pred_comressed:0\n",
      "pred_np_model:[1]\n",
      "\n",
      "The 4-th ins:\n",
      "fx_compressed:[-30.62108772]\n",
      "fx_np_model:[-2.14699336]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 5-th ins:\n",
      "fx_compressed:[-27.17903565]\n",
      "fx_np_model:[-1.51682963]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 6-th ins:\n",
      "fx_compressed:[-27.87745514]\n",
      "fx_np_model:[-1.84686507]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 7-th ins:\n",
      "fx_compressed:[-25.81953582]\n",
      "fx_np_model:[1.06113959]\n",
      "pred_comressed:0\n",
      "pred_np_model:[1]\n",
      "\n",
      "The 8-th ins:\n",
      "fx_compressed:[-27.57246415]\n",
      "fx_np_model:[-1.8236303]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "\n",
      "The 9-th ins:\n",
      "fx_compressed:[-28.61438548]\n",
      "fx_np_model:[-1.76943493]\n",
      "pred_comressed:0\n",
      "pred_np_model:[0]\n",
      "Acc:0.81\n"
     ]
    }
   ],
   "source": [
    "for name in traverse_list:\n",
    "    n_features = datasets[name]['n_features']\n",
    "    is_multi = datasets[name]['is_multi']\n",
    "    has_test = datasets[name]['has_test']\n",
    "\n",
    "    # -------------------\n",
    "    # Load Data\n",
    "    # -------------------\n",
    "\n",
    "    print('...Load data')\n",
    "    X_train, y_train, X_test, y_test = get_libsvm_data(name, n_features, is_multi, has_test)\n",
    "\n",
    "    # -------------------\n",
    "    # Train np model\n",
    "    # -------------------\n",
    "\n",
    "    print('\\n... Train np model')\n",
    "    np_model = construct_np_model(model_type=model_type, kernel=kernel)\n",
    "    np_model = train_np_model(np_model, X_train, y_train)\n",
    "    eval_np_model(np_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # 获取参数并计算fx\n",
    "    X_fit = X_train[np_model.support_]\n",
    "    y_fit = y_train[np_model.support_]\n",
    "    params = np_model.get_params()\n",
    "    if 'gamma' in params:\n",
    "        params['gamma'] = 1/(n_features * X_train.var()) if params['gamma'] == 'scale' else params['gamma']\n",
    "    coef = np_model.dual_coef_\n",
    "    intercept = np_model.intercept_\n",
    "    \n",
    "    km = cal_km(params, X_fit, X_test[:10], type='realize')\n",
    "    fx = cal_fx(km, coef, intercept)\n",
    "    print('\\nfx-realize:')\n",
    "    print(fx)\n",
    "    print('\\ndecision_function:')\n",
    "    print(np_model.decision_function(X_test[:10]))\n",
    "    print('\\ny_pred')\n",
    "    print(np_model.predict(X_test[:10]))\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------\n",
    "    # Pre-processing\n",
    "    # -------------------\n",
    "\n",
    "    print('\\n...Pre-processing')\n",
    "    # 根据coef对X_fit等升序排序\n",
    "    sorted_idx = np.argsort(coef[0])\n",
    "    sorted_coef = coef[0][sorted_idx].reshape(-1, 1)\n",
    "    sorted_X_fit = X_fit[sorted_idx]\n",
    "    sorted_y_fit = y_fit[sorted_idx]\n",
    "\n",
    "    # 舍弃低权重的instance\n",
    "    fit_dataloaders, n_fit = get_fit_dataloaders(sorted_X_fit, sorted_coef, sorted_y_fit, _config.labels, map_size)\n",
    "\n",
    "    # 展示原分布\n",
    "    print('\\ndata distribution compare:')\n",
    "    print('train data - num:{}, distribution:{}'.format(X_train.shape[0], sorted(Counter(y_train).items())))\n",
    "    print('fit data - num:{}, distribution:{}'.format(X_fit.shape[0], sorted(Counter(y_fit).items())))\n",
    "\n",
    "\n",
    "    # -------------------\n",
    "    # Compressing && Inference\n",
    "    # -------------------\n",
    "\n",
    "    for rate in rate_list:\n",
    "        start = time.time()\n",
    "\n",
    "        # 计算每个map压缩的数量\n",
    "        n_compressed = X_fit.shape[0] * (1-rate)\n",
    "        rate = n_compressed / n_fit\n",
    "        n_generate = int(rate*map_size)\n",
    "\n",
    "        # 初始化压缩表示\n",
    "        X_compressed = None\n",
    "        y_compressed = None\n",
    "        coef_compressed = None\n",
    "        is_none = True\n",
    "\n",
    "        # 对于所有label\n",
    "        for label in labels:\n",
    "            fit_dataloader = fit_dataloaders[label]\n",
    "            # 对于每个batch\n",
    "            for data in fit_dataloader:\n",
    "                X_map, coef_map = data\n",
    "                coef_map = coef_map.view(1,-1)\n",
    "\n",
    "                #初始化网络\n",
    "                conv_module = CNN_Res18(Basic_Block, blocks, n_generate)\n",
    "                compression_net = CompressionNet(conv_module, X_map, label, lr, n_generate, params)\n",
    "\n",
    "            #     for name, param in compression_net.named_parameters():\n",
    "            #         print(name)\n",
    "            #     break\n",
    "            # break\n",
    "\n",
    "                # 初始化数据\n",
    "                gdm = GeneralDataModule(n_features,n_classes,labels,batch_size=64)\n",
    "                gdm.prepare_data(X_train, X_test, params, X_map[0][0].numpy(), coef_map.numpy(), label)\n",
    "\n",
    "                #训练\n",
    "                trainer = pl.Trainer(callbacks=[early_stop_callback], max_epochs=1)\n",
    "                trainer.fit(compression_net, gdm) #单轮测试\n",
    "\n",
    "                #测试\n",
    "                trainer.test(datamodule=gdm)\n",
    "\n",
    "                # 保存压缩向量\n",
    "                X_compressed_partial =compression_net.forward().cpu().detach().numpy()\n",
    "                y_compressed_partial = np.full((X_compressed_partial.shape[0],),label)\n",
    "                alpha_i_compressed_partial = compression_net.get_alpha_i().cpu().detach().numpy()\n",
    "                label_i = 1 if label > 0 else -1\n",
    "                coef_compressed_partial = alpha_i_compressed_partial * label_i\n",
    "\n",
    "\n",
    "                if is_none:\n",
    "                    X_compressed = X_compressed_partial\n",
    "                    coef_compressed = coef_compressed_partial\n",
    "                    y_compressed = y_compressed_partial\n",
    "                    is_none = False\n",
    "                else:\n",
    "                    X_compressed = np.concatenate((X_compressed,X_compressed_partial),axis=0)\n",
    "                    coef_compressed = np.concatenate((coef_compressed,coef_compressed_partial),axis=0)\n",
    "                    y_compressed = np.concatenate((y_compressed,y_compressed_partial),axis=0)\n",
    "                \n",
    "                break\n",
    "            break\n",
    "\n",
    "        end = time.time()\n",
    "        print('\\nTraining time used:{:.2f}'.format(end-start))\n",
    "        print('-------------------')\n",
    "\n",
    "        # 使用coef_compressed 和 X_compressed 来计算fx\n",
    "        start = time.time()\n",
    "        print('\\n eval compressed ins')\n",
    "        n_true = 0\n",
    "        for i in range(X_test.shape[0]):\n",
    "            km_compressed = cal_km(params, X_compressed, X_test[i].reshape(1,-1), type='interface')\n",
    "            fx_compressed = cal_fx(km_compressed, coef_compressed, intercept=0)\n",
    "            pred_compressed = 1 if fx_compressed > 0 else 0\n",
    "            y_pred = np_model.predict(X_test[i].reshape(1,-1))\n",
    "            if pred_compressed == y_pred:\n",
    "                n_true = n_true + 1 \n",
    "\n",
    "            if i < 10:\n",
    "                print('\\nThe {}-th ins:'.format(i))\n",
    "                print('fx_compressed:{}'.format(fx_compressed))\n",
    "                print('fx_np_model:{}'.format(np_model.decision_function(X_test[i].reshape(1,-1)))) \n",
    "                print('pred_comressed:{}'.format(pred_compressed))\n",
    "                print('pred_np_model:{}'.format(y_pred))\n",
    "        \n",
    "        end = time.time()\n",
    "        print('\\nTraining time used:{:.2f}'.format(end-start))\n",
    "        print('On compression rate {}, Acc:{:.2f}'.format(rate, n_true/X_test.shape[0]))\n",
    "        print('-------------------------')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### splice test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...Load data\n",
      "Loading Finish: Time used 0.31\n",
      "---Dataset Info---\n",
      "dataset name:a9a\n",
      "n_features:123\n",
      "is_multi:False\n",
      "Trainset:[(0, 24720), (1, 7841)]\n",
      "Testset:[(0, 12435), (1, 3846)]\n",
      "\n",
      "... Train np model\n",
      "Training Finish: Time used 2.33\n",
      "dataset   \tacc       \tprecision \trecall    \tf1-score  \n",
      "trainset  \t0.86      \t0.82      \t0.78      \t0.80      \n",
      "testset   \t0.85      \t0.80      \t0.76      \t0.78      \n",
      "\n",
      "fx-realize:\n",
      "[-1.65739295 -1.10803564 -0.27469856  0.64455147 -2.14699336 -1.51682963\n",
      " -1.84686507  1.06113959 -1.8236303  -1.76943493]\n",
      "\n",
      "decision_function:\n",
      "[-1.65739295 -1.10803564 -0.27469856  0.64455147 -2.14699336 -1.51682963\n",
      " -1.84686507  1.06113959 -1.8236303  -1.76943493]\n",
      "\n",
      "y_pred\n",
      "[0 0 0 1 0 0 0 1 0 0]\n",
      "\n",
      "...Pre-processing\n",
      "----label 0----\n",
      "before X_temp_shape: (6118, 123)\n",
      "before coef_temp_shape: (6118, 1)\n",
      "after X_temp_shape: (6016, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 47.0\n",
      "47 map for each 128 item,total 6016\n",
      "batch X_temp_shape: (47, 1, 128, 123)\n",
      "batch coef_temp_shape: (47, 128, 1)\n",
      "----label 1----\n",
      "before X_temp_shape: (5632, 123)\n",
      "before coef_temp_shape: (5632, 1)\n",
      "after X_temp_shape: (5632, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 44.0\n",
      "44 map for each 128 item,total 5632\n",
      "batch X_temp_shape: (44, 1, 128, 123)\n",
      "batch coef_temp_shape: (44, 128, 1)\n",
      "\n",
      "data distribution compare:\n",
      "train data - num:32561, distribution:[(0, 24720), (1, 7841)]\n",
      "fit data - num:11750, distribution:[(0, 6118), (1, 5632)]\n"
     ]
    }
   ],
   "source": [
    "name = 'a9a'\n",
    "\n",
    "n_features = datasets[name]['n_features']\n",
    "is_multi = datasets[name]['is_multi']\n",
    "has_test = datasets[name]['has_test']\n",
    "\n",
    "# -------------------\n",
    "# Load Data\n",
    "# -------------------\n",
    "\n",
    "print('...Load data')\n",
    "X_train, y_train, X_test, y_test = get_libsvm_data(name, n_features, is_multi, has_test)\n",
    "\n",
    "# -------------------\n",
    "# Train np model\n",
    "# -------------------\n",
    "\n",
    "print('\\n... Train np model')\n",
    "np_model = construct_np_model(model_type=model_type, kernel=kernel)\n",
    "np_model = train_np_model(np_model, X_train, y_train)\n",
    "eval_np_model(np_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 获取参数并计算fx\n",
    "X_fit = X_train[np_model.support_]\n",
    "y_fit = y_train[np_model.support_]\n",
    "params = np_model.get_params()\n",
    "if 'gamma' in params:\n",
    "    params['gamma'] = 1/(n_features * X_train.var()) if params['gamma'] == 'scale' else params['gamma']\n",
    "coef = np_model.dual_coef_\n",
    "intercept = np_model.intercept_\n",
    "\n",
    "km = cal_km(params, X_fit, X_test[:10], type='realize')\n",
    "fx = cal_fx(km, coef, intercept)\n",
    "print('\\nfx-realize:')\n",
    "print(fx)\n",
    "print('\\ndecision_function:')\n",
    "print(np_model.decision_function(X_test[:10]))\n",
    "print('\\ny_pred')\n",
    "print(np_model.predict(X_test[:10]))\n",
    "\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Pre-processing\n",
    "# -------------------\n",
    "\n",
    "print('\\n...Pre-processing')\n",
    "# 根据coef对X_fit等升序排序\n",
    "sorted_idx = np.argsort(coef[0])\n",
    "sorted_coef = coef[0][sorted_idx].reshape(-1, 1)\n",
    "sorted_X_fit = X_fit[sorted_idx]\n",
    "sorted_y_fit = y_fit[sorted_idx]\n",
    "\n",
    "# 舍弃低权重的instance\n",
    "fit_dataloaders, n_fit = get_fit_dataloaders(sorted_X_fit, sorted_coef, sorted_y_fit, _config.labels, map_size)\n",
    "\n",
    "# 展示原分布\n",
    "print('\\ndata distribution compare:')\n",
    "print('train data - num:{}, distribution:{}'.format(X_train.shape[0], sorted(Counter(y_train).items())))\n",
    "print('fit data - num:{}, distribution:{}'.format(X_fit.shape[0], sorted(Counter(y_fit).items())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name | Type      | Params\n",
      "-----------------------------------\n",
      "0 | conv | CNN_Res18 | 175 K \n",
      "-----------------------------------\n",
      "175 K     Trainable params\n",
      "0         Non-trainable params\n",
      "175 K     Total params\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea58bbc79bef4cea8cfe086595b76081"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67c1deaee9e84b5f8cedb931c0193791"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nInitial coef:\nParameter containing:\ntensor([[0.0357, 0.3764, 0.1085, 0.3252, 0.6649, 0.4718, 0.6153, 0.8656, 0.0341,\n         0.8161, 0.5587, 0.3541, 0.8191, 0.5575, 0.4546, 0.1656, 0.6378, 0.0809,\n         0.3949, 0.4231, 0.7205, 0.6089, 0.6168, 0.3927, 0.4087, 0.3637, 0.7704,\n         0.8593, 0.9399, 0.7215, 0.9139, 0.1826, 0.7845, 0.9045, 0.9869, 0.9209,\n         0.3893, 0.5479, 0.9396, 0.1038, 0.8510, 0.1102, 0.3595, 0.6568, 0.2958,\n         0.2678, 0.6338, 0.4295, 0.7308, 0.8843, 0.7305, 0.0700, 0.2721, 0.2150,\n         0.5847, 0.3790, 0.7648, 0.3556, 0.0233, 0.0426, 0.4567, 0.2930, 0.1520,\n         0.2856]], requires_grad=True)\n\nInitial alpha_i:\ntensor([[0.0095, 0.0134, 0.0102, 0.0127, 0.0178, 0.0147, 0.0170, 0.0218, 0.0095,\n         0.0207, 0.0160, 0.0131, 0.0208, 0.0160, 0.0144, 0.0108, 0.0173, 0.0099,\n         0.0136, 0.0140, 0.0188, 0.0168, 0.0170, 0.0136, 0.0138, 0.0132, 0.0198,\n         0.0216, 0.0235, 0.0189, 0.0229, 0.0110, 0.0201, 0.0226, 0.0246, 0.0230,\n         0.0135, 0.0158, 0.0234, 0.0102, 0.0215, 0.0102, 0.0131, 0.0177, 0.0123,\n         0.0120, 0.0173, 0.0141, 0.0190, 0.0222, 0.0190, 0.0098, 0.0120, 0.0114,\n         0.0164, 0.0134, 0.0197, 0.0131, 0.0094, 0.0096, 0.0145, 0.0123, 0.0107,\n         0.0122]], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23c6aa7bb1654e6faf08f62902bc4202"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nAfter train coef:\nParameter containing:\ntensor([[ 3.8794,  3.8427,  3.9198,  3.9491,  3.9733,  4.1019,  3.9741,  3.9114,\n          3.9653,  3.6270,  3.9468,  3.7841,  4.0184,  3.9608,  3.9734,  3.9040,\n          3.9329,  3.8928,  3.8687,  3.9329,  3.8442,  4.0855,  3.6466,  3.9066,\n          3.9551,  3.9417,  3.9479,  3.8579,  3.9304,  3.9651,  4.0267,  3.9368,\n          3.7445,  3.9787,  3.8788,  3.9598,  3.9317,  3.9348,  3.8551,  3.7338,\n          3.9246,  3.7596,  3.9551,  3.9733,  4.0089,  3.9470,  3.9615,  3.9791,\n          3.9552,  3.9262,  3.9263,  3.9649,  3.9736,  3.9679,  3.9294,  3.8666,\n          3.9472,  4.1321, -0.0052,  3.9798,  3.9717,  3.8591,  3.8593,  3.9570]],\n       requires_grad=True)\n\nAfter train alpha_i:\ntensor([[0.0151, 0.0146, 0.0158, 0.0162, 0.0166, 0.0189, 0.0166, 0.0156, 0.0165,\n         0.0118, 0.0162, 0.0138, 0.0174, 0.0164, 0.0166, 0.0155, 0.0160, 0.0153,\n         0.0150, 0.0160, 0.0146, 0.0186, 0.0120, 0.0156, 0.0163, 0.0161, 0.0162,\n         0.0148, 0.0159, 0.0165, 0.0175, 0.0160, 0.0132, 0.0167, 0.0151, 0.0164,\n         0.0159, 0.0160, 0.0148, 0.0131, 0.0158, 0.0134, 0.0163, 0.0166, 0.0172,\n         0.0162, 0.0164, 0.0167, 0.0163, 0.0159, 0.0159, 0.0165, 0.0166, 0.0165,\n         0.0159, 0.0149, 0.0162, 0.0195, 0.0003, 0.0167, 0.0166, 0.0148, 0.0148,\n         0.0164]], grad_fn=<SoftmaxBackward>)\n\n loss grads:\ntensor(1.)\n\n fx_hat grads:\ntensor([0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n        0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n        0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n        0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278])\n\n coef grads:\ntensor([[0.3237, 0.3237, 0.4860, 0.4852, 0.4862, 0.3237, 0.4864, 0.4868, 0.4863,\n         0.3237, 0.4867, 0.3237, 0.4866, 0.4861, 0.4862, 0.4868, 0.4865, 0.3237,\n         0.4863, 0.4861, 0.3237, 0.4868, 0.3237, 0.4869, 0.4862, 0.4861, 0.4862,\n         0.3237, 0.4863, 0.4870, 0.4868, 0.4866, 0.3237, 0.4861, 0.4870, 0.4859,\n         0.4860, 0.4869, 0.3237, 0.3237, 0.4868, 0.3237, 0.4864, 0.4870, 0.4862,\n         0.4863, 0.4860, 0.4857, 0.4861, 0.4870, 0.4860, 0.4851, 0.4861, 0.4855,\n         0.4861, 0.3237, 0.4849, 0.4867, 0.0415, 0.4860, 0.4861, 0.4863, 0.4863,\n         0.4863]])\n\n constrainted_alpha_i grads:\ntensor([[-0.3237, -0.3237, -0.4860, -0.4852, -0.4862, -0.3237, -0.4864, -0.4868,\n         -0.4863, -0.3237, -0.4867, -0.3237, -0.4866, -0.4861, -0.4862, -0.4868,\n         -0.4865, -0.3237, -0.4863, -0.4861, -0.3237, -0.4868, -0.3237, -0.4869,\n         -0.4862, -0.4861, -0.4862, -0.3237, -0.4863, -0.4870, -0.4868, -0.4866,\n         -0.3237, -0.4861, -0.4870, -0.4859, -0.4860, -0.4869, -0.3237, -0.3237,\n         -0.4868, -0.3237, -0.4864, -0.4870, -0.4862, -0.4863, -0.4860, -0.4857,\n         -0.4861, -0.4870, -0.4860, -0.4851, -0.4861, -0.4855, -0.4861, -0.3237,\n         -0.4849, -0.4867, -0.0415, -0.4860, -0.4861, -0.4863, -0.4863, -0.4863]])\n\n alpha_i grads:\ntensor([[-0.0781, -0.0781, -0.1173, -0.1171, -0.1173, -0.0781, -0.1174, -0.1175,\n         -0.1174, -0.0781, -0.1175, -0.0781, -0.1174, -0.1173, -0.1173, -0.1175,\n         -0.1174, -0.0781, -0.1174, -0.1173, -0.0781,  6.3644, -0.0781, -0.1175,\n         -0.1173, -0.1173, -0.1173, -0.0781, -0.1173, -0.1175, -0.1175, -0.1174,\n         -0.0781, -0.1173, -0.1175, -0.1173, -0.1173, -0.1175, -0.0781, -0.0781,\n         -0.1175, -0.0781, -0.1174, -0.1175, -0.1173, -0.1174, -0.1173, -0.1172,\n         -0.1173, -0.1175, -0.1173, -0.1171, -0.1173, -0.1172, -0.1173, -0.0781,\n         -0.1170, -0.1175,  0.3622, -0.1173, -0.1173, -0.1174, -0.1173, -0.1174]])\n\n km grads:\ntensor([[-0.0259, -0.0259, -0.0259,  ..., -0.0259, -0.0259, -0.0259],\n        [-0.0259, -0.0259, -0.0259,  ..., -0.0259, -0.0259, -0.0259],\n        [-0.0262, -0.0262, -0.0262,  ..., -0.0262, -0.0262, -0.0262],\n        ...,\n        [-0.0258, -0.0258, -0.0258,  ..., -0.0258, -0.0258, -0.0258],\n        [-0.0258, -0.0258, -0.0258,  ..., -0.0258, -0.0258, -0.0258],\n        [-0.0265, -0.0265, -0.0265,  ..., -0.0265, -0.0265, -0.0265]])\n\n X_compressed grads:\ntensor([[-0.0110, -0.0067, -0.0094,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0110, -0.0067, -0.0094,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0001,  0.0061,  0.0018,  ...,  0.0000,  0.0000,  0.0000],\n        ...,\n        [ 0.0003,  0.0065,  0.0022,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0002,  0.0064,  0.0021,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0001,  0.0064,  0.0021,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cec689d823714d95906a64e52971185c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_loss': tensor(40.4421),\n 'test_mae': tensor(40.9421),\n 'test_mse': tensor(1732.1364),\n 'test_var': tensor(0.0035),\n 'val_loss': tensor(38.6593),\n 'val_mae': tensor(39.1593),\n 'val_mse': tensor(1582.7970),\n 'val_var': tensor(0.0037)}\n--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Compressing && Inference\n",
    "# -------------------\n",
    "rate = 0.5\n",
    "# 计算每个map压缩的数量\n",
    "n_compressed = X_fit.shape[0] * (1-rate)\n",
    "rate = n_compressed / n_fit\n",
    "n_generate = int(rate*map_size)\n",
    "\n",
    "# 初始化压缩表示\n",
    "X_compressed = None\n",
    "y_compressed = None\n",
    "coef_compressed = None\n",
    "is_none = True\n",
    "\n",
    "# 对于所有label\n",
    "for label in labels:\n",
    "    fit_dataloader = fit_dataloaders[label]\n",
    "    # 对于每个batch\n",
    "    for data in fit_dataloader:\n",
    "        X_map, coef_map = data\n",
    "        coef_map = coef_map.view(1,-1)\n",
    "\n",
    "        #初始化网络\n",
    "        conv_module = CNN_Res18(Basic_Block, blocks, n_generate)\n",
    "        compression_net = CompressionNet(conv_module, X_map, label, lr, n_generate, params)\n",
    "\n",
    "    #     for name, param in compression_net.named_parameters():\n",
    "    #         print(name)\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "        # 初始化数据\n",
    "        gdm = GeneralDataModule(n_features,n_classes,labels,batch_size=64)\n",
    "        gdm.prepare_data(X_train, X_test, params, X_map[0][0].numpy(), coef_map.numpy(), label)\n",
    "\n",
    "        #训练\n",
    "        trainer = pl.Trainer(callbacks=[early_stop_callback], max_epochs=1)\n",
    "        trainer.fit(compression_net, gdm) #单轮测试\n",
    "\n",
    "        #测试\n",
    "        trainer.test(datamodule=gdm)\n",
    "\n",
    "        # 保存压缩向量\n",
    "        X_compressed_partial =compression_net.forward().cpu().detach().numpy()\n",
    "        y_compressed_partial = np.full((X_compressed_partial.shape[0],),label)\n",
    "        alpha_i_compressed_partial = compression_net.get_alpha_i().cpu().detach().numpy()\n",
    "        label_i = 1 if label > 0 else -1\n",
    "        coef_compressed_partial = alpha_i_compressed_partial * label_i\n",
    "\n",
    "\n",
    "        if is_none:\n",
    "            X_compressed = X_compressed_partial\n",
    "            coef_compressed = coef_compressed_partial\n",
    "            y_compressed = y_compressed_partial\n",
    "            is_none = False\n",
    "        else:\n",
    "            X_compressed = np.concatenate((X_compressed,X_compressed_partial),axis=0)\n",
    "            coef_compressed = np.concatenate((coef_compressed,coef_compressed_partial),axis=0)\n",
    "            y_compressed = np.concatenate((y_compressed,y_compressed_partial),axis=0)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n eval compressed ins\n\nThe 0-th ins:\nfx_compressed:[-0.42640049]\nfx_np_model:[-1.65739295]\npred_comressed:0\npred_np_model:[0]\n\nThe 1-th ins:\nfx_compressed:[-0.47882802]\nfx_np_model:[-1.10803564]\npred_comressed:0\npred_np_model:[0]\n\nThe 2-th ins:\nfx_compressed:[-0.42769892]\nfx_np_model:[-0.27469856]\npred_comressed:0\npred_np_model:[0]\n\nThe 3-th ins:\nfx_compressed:[-0.41869662]\nfx_np_model:[0.64455147]\npred_comressed:0\npred_np_model:[1]\n\nThe 4-th ins:\nfx_compressed:[-0.51302375]\nfx_np_model:[-2.14699336]\npred_comressed:0\npred_np_model:[0]\n\nThe 5-th ins:\nfx_compressed:[-0.45601776]\nfx_np_model:[-1.51682963]\npred_comressed:0\npred_np_model:[0]\n\nThe 6-th ins:\nfx_compressed:[-0.4659384]\nfx_np_model:[-1.84686507]\npred_comressed:0\npred_np_model:[0]\n\nThe 7-th ins:\nfx_compressed:[-0.43205044]\nfx_np_model:[1.06113959]\npred_comressed:0\npred_np_model:[1]\n\nThe 8-th ins:\nfx_compressed:[-0.45637356]\nfx_np_model:[-1.8236303]\npred_comressed:0\npred_np_model:[0]\n\nThe 9-th ins:\nfx_compressed:[-0.47680964]\nfx_np_model:[-1.76943493]\npred_comressed:0\npred_np_model:[0]\n"
     ]
    }
   ],
   "source": [
    "# 使用coef_compressed 和 X_compressed 来计算fx\n",
    "print('\\n eval compressed ins')\n",
    "n_true = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    km_compressed = cal_km(params, X_compressed, X_test[i].reshape(1,-1), type='interface')\n",
    "    fx_compressed = cal_fx(km_compressed, coef_compressed, intercept=0)\n",
    "    pred_compressed = 1 if fx_compressed > 0 else 0\n",
    "    y_pred = np_model.predict(X_test[i].reshape(1,-1))\n",
    "    if pred_compressed == y_pred:\n",
    "        n_true = n_true + 1 \n",
    "\n",
    "    if i < 10:\n",
    "        print('\\nThe {}-th ins:'.format(i))\n",
    "        print('fx_compressed:{}'.format(fx_compressed))\n",
    "        print('fx_np_model:{}'.format(np_model.decision_function(X_test[i].reshape(1,-1)))) \n",
    "        print('pred_comressed:{}'.format(pred_compressed))\n",
    "        print('pred_np_model:{}'.format(y_pred))\n",
    "        \n",
    "print('Acc:{:.2f}'.format(n_true/X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "source": [
    "## Check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  name  \tn_features\tis_multi\t          trainset          \t          testset           \n",
      "  a9a   \t  123   \t   0    \t  [(0, 24720), (1, 7841)]   \t  [(0, 12435), (1, 3846)]   \n",
      " ijcnn1 \t   22   \t   0    \t  [(0, 45137), (1, 4853)]   \t  [(0, 82989), (1, 8712)]   \n",
      "madelon \t  500   \t   0    \t   [(0, 1000), (1, 1000)]   \t    [(0, 300), (1, 300)]    \n",
      "mushrooms\t  112   \t   0    \t   [(0, 2738), (1, 2948)]   \t   [(0, 1178), (1, 1260)]   \n",
      "phishing\t   68   \t   0    \t   [(0, 3452), (1, 4286)]   \t   [(0, 1446), (1, 1871)]   \n",
      " splice \t   60   \t   0    \t    [(0, 333), (1, 367)]    \t    [(0, 150), (1, 150)]    \n",
      "  w8a   \t  300   \t   0    \t  [(0, 48270), (1, 1479)]   \t   [(0, 14497), (1, 454)]   \n",
      "dna.scale\t  180   \t   1    \t   [(0, 949), (1, 1051)]    \t    [(0, 583), (1, 603)]    \n",
      " mnist  \t  780   \t   1    \t  [(0, 54051), (1, 5949)]   \t   [(0, 8991), (1, 1009)]   \n",
      "pendigits\t   16   \t   1    \t   [(0, 6775), (1, 719)]    \t   [(0, 3162), (1, 336)]    \n",
      "Sensorless\t   48   \t   1    \t  [(0, 37232), (1, 3724)]   \t  [(0, 15958), (1, 1595)]   \n",
      "  usps  \t  256   \t   1    \t   [(0, 6647), (1, 644)]    \t   [(0, 1830), (1, 177)]    \n"
     ]
    }
   ],
   "source": [
    "# check datasets\n",
    "from utils.check import check_datasets\n",
    "check_datasets()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Finish: Time used 0.31\n",
      "---Dataset Info---\n",
      "dataset name:a9a\n",
      "n_features:123\n",
      "is_multi:False\n",
      "Trainset:[(0, 24720), (1, 7841)]\n",
      "Testset:[(0, 12435), (1, 3846)]\n",
      "---linear svc---\n",
      "Training Finish: Time used 4.01\n",
      "dataset   \tacc       \tprecision \trecall    \tf1-score  \n",
      "trainset  \t0.85      \t0.80      \t0.76      \t0.78      \n",
      "testset   \t0.85      \t0.80      \t0.76      \t0.78      \n",
      "max_alpha_i:1.0\n",
      "min_alpha_i:0.0007892183376909667\n",
      "---rbf svc---\n",
      "Training Finish: Time used 1.90\n",
      "dataset   \tacc       \tprecision \trecall    \tf1-score  \n",
      "trainset  \t0.86      \t0.82      \t0.78      \t0.80      \n",
      "testset   \t0.85      \t0.80      \t0.76      \t0.78      \n",
      "max_alpha_i:1.0\n",
      "min_alpha_i:0.0007575813783527016\n",
      "---poly svc---\n",
      "Training Finish: Time used 2.41\n",
      "dataset   \tacc       \tprecision \trecall    \tf1-score  \n",
      "trainset  \t0.87      \t0.83      \t0.79      \t0.80      \n",
      "testset   \t0.85      \t0.80      \t0.76      \t0.78      \n",
      "max_alpha_i:1.0\n",
      "min_alpha_i:0.0004075180053148361\n",
      "---sigmoid svc---\n",
      "Training Finish: Time used 0.54\n",
      "dataset   \tacc       \tprecision \trecall    \tf1-score  \n",
      "trainset  \t0.78      \t0.70      \t0.70      \t0.70      \n",
      "testset   \t0.79      \t0.70      \t0.70      \t0.70      \n",
      "max_alpha_i:1.0\n",
      "min_alpha_i:0.1596548097749964\n"
     ]
    }
   ],
   "source": [
    "# check np model training and fx function\n",
    "from utils.check import check_np_traning\n",
    "check_np_traning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------linear---------\n",
      "Training Finish: Time used 4.00\n",
      "----show kernel metrics---\n",
      "\n",
      " sklearn:\n",
      "[[14.  7.  7. ...  4.  8.  8.]\n",
      " [ 7. 14.  5. ... 10.  5.  9.]\n",
      " [ 4.  5.  4. ...  3.  6.  6.]\n",
      " ...\n",
      " [ 5.  8.  6. ...  8.  5.  8.]\n",
      " [ 3.  5.  6. ...  6.  6.  5.]\n",
      " [ 6.  7. 10. ...  9.  4.  8.]]\n",
      "(11518, 10)\n",
      "\n",
      " realize:\n",
      "[[14.  7.  7. ...  4.  8.  8.]\n",
      " [ 7. 14.  5. ... 10.  5.  9.]\n",
      " [ 4.  5.  4. ...  3.  6.  6.]\n",
      " ...\n",
      " [ 5.  8.  6. ...  8.  5.  8.]\n",
      " [ 3.  5.  6. ...  6.  6.  5.]\n",
      " [ 6.  7. 10. ...  9.  4.  8.]]\n",
      "(11518, 10)\n",
      "\n",
      "---show hand-10 fx ---\n",
      "\n",
      " fx_interface:\n",
      "[-0.32197564 -0.21942202 -2.52409056 -1.27149923  0.459413    1.24033194\n",
      " -4.45229551 -0.11865911 -0.15206388  2.18820474]\n",
      "\n",
      " fx_realize:\n",
      "[-0.32197564 -0.21942202 -2.52409056 -1.27149923  0.459413    1.24033194\n",
      " -4.45229551 -0.11865911 -0.15206388  2.18820474]\n",
      "\n",
      " decsion function:\n",
      "[-0.32197564 -0.21942202 -2.52409056 -1.27149923  0.459413    1.24033194\n",
      " -4.45229551 -0.11865911 -0.15206388  2.18820474]\n",
      "\n",
      " y_pred:\n",
      "[0 0 0 0 1 1 0 0 0 1]\n",
      "\n",
      "---show composite fx---\n",
      "\n",
      " fx1-5000 ins\n",
      "[-415.13202325 -609.25606218 -354.36998769 -507.87449916 -413.24584171\n",
      " -406.36426183 -181.39721669 -471.84819369 -416.35226737 -605.08768339]\n",
      "\n",
      " fx2-others\n",
      "[416.37620836 610.60280091 353.41205789 508.16916069 415.27141547\n",
      " 409.17075451 178.51108192 473.29569533 417.76636424 608.84204888]\n",
      "\n",
      " batch fx = fx1 + fx2 + intercept\n",
      "[-0.32197564 -0.21942202 -2.52409056 -1.27149923  0.459413    1.24033194\n",
      " -4.45229551 -0.11865911 -0.15206388  2.18820474]\n",
      "\n",
      "-----------------\n",
      " \n",
      "--------rbf---------\n",
      "Training Finish: Time used 1.90\n",
      "----show kernel metrics---\n",
      "\n",
      " sklearn:\n",
      "[[1.         0.32054775 0.32054775 ... 0.19684866 0.37711993 0.37711993]\n",
      " [0.32054775 1.         0.23158969 ... 0.52197895 0.23158969 0.4436763 ]\n",
      " [0.19684866 0.23158969 0.19684866 ... 0.16731918 0.27246202 0.27246202]\n",
      " ...\n",
      " [0.23158969 0.37711993 0.27246202 ... 0.37711993 0.23158969 0.37711993]\n",
      " [0.16731918 0.23158969 0.27246202 ... 0.27246202 0.27246202 0.23158969]\n",
      " [0.27246202 0.32054775 0.52197895 ... 0.4436763  0.19684866 0.37711993]]\n",
      "(11750, 10)\n",
      "\n",
      " realize:\n",
      "[[1.         0.32054775 0.32054775 ... 0.19684866 0.37711993 0.37711993]\n",
      " [0.32054775 1.         0.23158969 ... 0.52197895 0.23158969 0.4436763 ]\n",
      " [0.19684866 0.23158969 0.19684866 ... 0.16731918 0.27246202 0.27246202]\n",
      " ...\n",
      " [0.23158969 0.37711993 0.27246202 ... 0.37711993 0.23158969 0.37711993]\n",
      " [0.16731918 0.23158969 0.27246202 ... 0.27246202 0.27246202 0.23158969]\n",
      " [0.27246202 0.32054775 0.52197895 ... 0.4436763  0.19684866 0.37711993]]\n",
      "(11750, 10)\n",
      "\n",
      "---show hand-10 fx ---\n",
      "\n",
      " fx_interface:\n",
      "[-0.72202023 -0.87759813 -1.29693308 -1.09318416  0.05132125  1.09500298\n",
      " -1.38940539 -0.44348122 -0.02525147  1.85557723]\n",
      "\n",
      " fx_realize:\n",
      "[-0.72202023 -0.87759813 -1.29693308 -1.09318416  0.05132125  1.09500298\n",
      " -1.38940539 -0.44348122 -0.02525147  1.85557723]\n",
      "\n",
      " decsion function:\n",
      "[-0.72202023 -0.87759813 -1.29693308 -1.09318416  0.05132125  1.09500298\n",
      " -1.38940539 -0.44348122 -0.02525147  1.85557723]\n",
      "\n",
      " y_pred:\n",
      "[0 0 0 0 1 1 0 0 0 1]\n",
      "\n",
      "---show composite fx---\n",
      "\n",
      " fx1-5000 ins\n",
      "[-21.16436444 -26.16436737 -15.538226   -18.57946197 -19.81408169\n",
      " -18.92657054 -10.97225213 -16.80228679 -22.11501866 -25.86352403]\n",
      "\n",
      " fx2-others\n",
      "[20.84095797 25.685383   14.63990668 17.88489157 20.2640167  20.42018728\n",
      "  9.9814605  16.75741934 22.48838096 28.11771502]\n",
      "\n",
      " batch fx = fx1 + fx2 + intercept\n",
      "[-0.72202023 -0.87759813 -1.29693308 -1.09318416  0.05132125  1.09500298\n",
      " -1.38940539 -0.44348122 -0.02525147  1.85557723]\n",
      "\n",
      "-----------------\n",
      " \n",
      "--------poly---------\n",
      "Training Finish: Time used 2.41\n",
      "----show kernel metrics---\n",
      "\n",
      " sklearn:\n",
      "[[1.47268818 0.18408602 0.18408602 ... 0.03434841 0.2747873  0.2747873 ]\n",
      " [0.18408602 1.47268818 0.06708674 ... 0.53669394 0.06708674 0.39124988]\n",
      " [0.03434841 0.06708674 0.03434841 ... 0.01449074 0.11592589 0.11592589]\n",
      " ...\n",
      " [0.06708674 0.2747873  0.11592589 ... 0.2747873  0.06708674 0.2747873 ]\n",
      " [0.01449074 0.06708674 0.11592589 ... 0.11592589 0.11592589 0.06708674]\n",
      " [0.11592589 0.18408602 0.53669394 ... 0.39124988 0.03434841 0.2747873 ]]\n",
      "(11726, 10)\n",
      "\n",
      " realize:\n",
      "[[1.47268818 0.18408602 0.18408602 ... 0.03434841 0.2747873  0.2747873 ]\n",
      " [0.18408602 1.47268818 0.06708674 ... 0.53669394 0.06708674 0.39124988]\n",
      " [0.03434841 0.06708674 0.03434841 ... 0.01449074 0.11592589 0.11592589]\n",
      " ...\n",
      " [0.06708674 0.2747873  0.11592589 ... 0.2747873  0.06708674 0.2747873 ]\n",
      " [0.01449074 0.06708674 0.11592589 ... 0.11592589 0.11592589 0.06708674]\n",
      " [0.11592589 0.18408602 0.53669394 ... 0.39124988 0.03434841 0.2747873 ]]\n",
      "(11726, 10)\n",
      "\n",
      "---show hand-10 fx ---\n",
      "\n",
      " fx_interface:\n",
      "[-0.94652727 -0.8946703  -1.27979186 -1.0588445  -0.21988244  1.15092558\n",
      " -0.99974295 -0.44308458 -0.09258198  1.79481011]\n",
      "\n",
      " fx_realize:\n",
      "[-0.94652727 -0.8946703  -1.27979186 -1.0588445  -0.21988244  1.15092558\n",
      " -0.99974295 -0.44308458 -0.09258198  1.79481011]\n",
      "\n",
      " decsion function:\n",
      "[-0.94652727 -0.8946703  -1.27979186 -1.0588445  -0.21988244  1.15092558\n",
      " -0.99974295 -0.44308458 -0.09258198  1.79481011]\n",
      "\n",
      " y_pred:\n",
      "[0 0 0 0 0 1 0 0 0 1]\n",
      "\n",
      "---show composite fx---\n",
      "\n",
      " fx1-5000 ins\n",
      "[-14.20825217 -21.09584524  -0.71070452  -5.82624887 -10.50873572\n",
      "  -9.3329405   -1.04461556   0.42647386 -16.21759511 -20.30145331]\n",
      "\n",
      " fx2-others\n",
      "[14.04802851 20.98747856  0.21721627  5.55370798 11.0751569  11.2701697\n",
      "  0.83117622 -0.08325483 16.91131674 22.88256703]\n",
      "\n",
      " batch fx = fx1 + fx2 + intercept\n",
      "[-0.94652727 -0.8946703  -1.27979186 -1.0588445  -0.21988244  1.15092558\n",
      " -0.99974295 -0.44308458 -0.09258198  1.79481011]\n",
      "\n",
      "-----------------\n",
      " \n",
      "--------sigmoid---------\n",
      "Training Finish: Time used 0.54\n",
      "----show kernel metrics---\n",
      "\n",
      " sklearn:\n",
      "[[0.51452305 0.81364629 0.3853521  ... 0.67105505 0.3853521  0.62391746]\n",
      " [0.51452305 0.3853521  0.81364629 ... 0.57175614 0.3853521  0.45230634]\n",
      " [0.31407862 0.67105505 0.57175614 ... 0.81364629 0.2390799  0.51452305]\n",
      " ...\n",
      " [0.3853521  0.57175614 0.45230634 ... 0.57175614 0.3853521  0.57175614]\n",
      " [0.45230634 0.51452305 0.67105505 ... 0.62391746 0.31407862 0.57175614]\n",
      " [0.3853521  0.3853521  0.57175614 ... 0.51452305 0.3853521  0.3853521 ]]\n",
      "(7396, 10)\n",
      "\n",
      " realize:\n",
      "[[0.51452305 0.81364629 0.3853521  ... 0.67105505 0.3853521  0.62391746]\n",
      " [0.51452305 0.3853521  0.81364629 ... 0.57175614 0.3853521  0.45230634]\n",
      " [0.31407862 0.67105505 0.57175614 ... 0.81364629 0.2390799  0.51452305]\n",
      " ...\n",
      " [0.3853521  0.57175614 0.45230634 ... 0.57175614 0.3853521  0.57175614]\n",
      " [0.45230634 0.51452305 0.67105505 ... 0.62391746 0.31407862 0.57175614]\n",
      " [0.3853521  0.3853521  0.57175614 ... 0.51452305 0.3853521  0.3853521 ]]\n",
      "(7396, 10)\n",
      "\n",
      "---show hand-10 fx ---\n",
      "\n",
      " fx_interface:\n",
      "[-18.26573313  20.11983322   0.74892127 -21.74120312 -15.63104414\n",
      "  -1.17275921 -58.9294703  -22.7483702  -43.19616821  23.83779337]\n",
      "\n",
      " fx_realize:\n",
      "[-18.26573313  20.11983322   0.74892127 -21.74120312 -15.63104414\n",
      "  -1.17275921 -58.9294703  -22.7483702  -43.19616821  23.83779337]\n",
      "\n",
      " decsion function:\n",
      "[-18.26573313  20.11983322   0.74892127 -21.74120312 -15.63104414\n",
      "  -1.17275921 -58.9294703  -22.7483702  -43.19616821  23.83779337]\n",
      "\n",
      " y_pred:\n",
      "[0 1 1 0 0 0 0 0 0 1]\n",
      "\n",
      "---show composite fx---\n",
      "\n",
      " fx1-5000 ins\n",
      "[-11.83649146  17.69350073   0.93997923  -9.90972731  -7.71924189\n",
      "  -2.86300397 -30.62330984 -12.65567348 -28.95760376  16.84331461]\n",
      "\n",
      " fx2-others\n",
      "[ 10.48270456  19.33827872  16.72088828   5.08047042   9.00014398\n",
      "  18.60219099 -11.39421422   6.81924951   2.67338177  23.90642498]\n",
      "\n",
      " batch fx = fx1 + fx2 + intercept\n",
      "[-18.26573313  20.11983322   0.74892127 -21.74120312 -15.63104414\n",
      "  -1.17275921 -58.9294703  -22.7483702  -43.19616821  23.83779337]\n",
      "\n",
      "-----------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from utils.check import check_kernel\n",
    "kernels = ['linear','rbf','poly','sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    print('--------{}---------'.format(kernel))\n",
    "    check_kernel(kernel, 'a9a')\n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Finish: Time used 2.27\n",
      "----label 0----\n",
      "before X_temp_shape: (6118, 123)\n",
      "before coef_temp_shape: (6118, 1)\n",
      "after X_temp_shape: (6016, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 47.0\n",
      "47 map for each 128 item,total 6016\n",
      "batch X_temp_shape: (47, 1, 128, 123)\n",
      "batch coef_temp_shape: (47, 128, 1)\n",
      "----label 1----\n",
      "before X_temp_shape: (5632, 123)\n",
      "before coef_temp_shape: (5632, 1)\n",
      "after X_temp_shape: (5632, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 44.0\n",
      "44 map for each 128 item,total 5632\n",
      "batch X_temp_shape: (44, 1, 128, 123)\n",
      "batch coef_temp_shape: (44, 128, 1)\n",
      "----data distribution----\n",
      "train data - num:32561, distribution:[0, 1]\n",
      "fit data - num:11750, distribution:[0, 1]\n",
      " \n",
      "torch.Size([116, 123])\n",
      "90.79% data - num:10556, distribution:[(0, 5452), (1, 5104)]\n",
      "torch.Size([103, 123])\n",
      "80.70% data - num:9373, distribution:[(0, 4841), (1, 4532)]\n",
      "torch.Size([90, 123])\n",
      "70.61% data - num:8190, distribution:[(0, 4230), (1, 3960)]\n",
      "torch.Size([77, 123])\n",
      "60.53% data - num:7007, distribution:[(0, 3619), (1, 3388)]\n",
      "torch.Size([64, 123])\n",
      "50.44% data - num:5824, distribution:[(0, 3008), (1, 2816)]\n",
      "torch.Size([51, 123])\n",
      "40.35% data - num:4641, distribution:[(0, 2397), (1, 2244)]\n",
      "torch.Size([38, 123])\n",
      "30.26% data - num:3458, distribution:[(0, 1786), (1, 1672)]\n",
      "torch.Size([25, 123])\n",
      "20.18% data - num:2275, distribution:[(0, 1175), (1, 1100)]\n",
      "torch.Size([12, 123])\n",
      "10.09% data - num:1092, distribution:[(0, 564), (1, 528)]\n"
     ]
    }
   ],
   "source": [
    "# conv module check\n",
    "from utils.check import conv_check\n",
    "conv_check('rbf', 'a9a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Finish: Time used 2.29\n",
      "----label 0----\n",
      "before X_temp_shape: (6118, 123)\n",
      "before coef_temp_shape: (6118, 1)\n",
      "after X_temp_shape: (6016, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 47.0\n",
      "47 map for each 128 item,total 6016\n",
      "batch X_temp_shape: (47, 1, 128, 123)\n",
      "batch coef_temp_shape: (47, 128, 1)\n",
      "----label 1----\n",
      "before X_temp_shape: (5632, 123)\n",
      "before coef_temp_shape: (5632, 1)\n",
      "after X_temp_shape: (5632, 123)\n",
      "after coef_shape: (11750, 1)\n",
      "n_parts: 44.0\n",
      "44 map for each 128 item,total 5632\n",
      "batch X_temp_shape: (44, 1, 128, 123)\n",
      "batch coef_temp_shape: (44, 128, 1)\n",
      "train data\n",
      "X size: torch.Size([64, 123])\n",
      "fx size: torch.Size([64])\n",
      "tensor([ 4.8923,  4.2217,  5.0499,  6.2265,  5.1495,  5.3396,  8.9146,  8.2607,\n",
      "        10.1467,  9.1276,  5.6376,  7.1242,  9.2530,  5.2876,  4.5125,  4.6420,\n",
      "         8.7168,  7.3550,  8.9088,  8.6178,  4.2905,  7.9247,  6.6408,  5.5920,\n",
      "         7.1739,  8.3154,  9.0454,  9.0461,  4.8636,  6.0341,  4.4665,  5.6854,\n",
      "         9.3873,  6.1502,  5.1669,  6.2281,  5.7838,  6.1298,  6.6500,  5.7926,\n",
      "         5.1891,  7.7101,  7.7817,  6.9620,  6.6175,  4.9838,  8.1037,  4.6756,\n",
      "         9.0608,  4.0783,  4.5676,  5.3473,  5.6150,  6.4701,  4.5298,  5.9214,\n",
      "         9.0200,  7.4964,  6.9454,  6.8306,  9.6333,  5.4891,  4.9730,  4.9547])\n",
      "val data\n",
      "torch.Size([64, 123])\n",
      "fx size: torch.Size([64])\n",
      "tensor([6.6613, 8.2151, 5.8903, 7.5008, 7.0597, 7.5619, 6.1671, 7.7883, 4.5686,\n",
      "        7.5469, 6.9573, 7.9288, 6.0760, 4.2411, 6.8856, 7.5076, 8.2151, 5.7785,\n",
      "        6.7755, 7.5875, 7.8599, 7.9684, 7.4743, 9.1628, 6.6672, 4.7297, 8.5438,\n",
      "        4.8615, 6.4269, 5.5609, 7.6316, 7.8064, 5.3838, 4.6540, 5.4386, 7.5282,\n",
      "        5.6922, 8.0894, 7.8538, 4.6792, 8.1911, 8.0511, 5.4794, 6.4118, 5.4175,\n",
      "        5.5133, 6.7265, 5.3529, 7.7970, 5.2637, 7.4784, 7.2618, 6.7138, 6.6022,\n",
      "        4.4010, 5.8300, 4.9971, 4.2155, 5.3198, 7.9238, 8.0689, 6.8466, 5.9042,\n",
      "        8.2206])\n",
      "test data\n",
      "torch.Size([64, 123])\n",
      "fx size: torch.Size([64])\n",
      "tensor([5.0807, 7.7917, 7.0092, 6.8389, 5.2598, 5.5600, 5.6232, 7.7099, 5.1527,\n",
      "        7.3076, 7.4218, 9.0262, 5.0462, 7.8622, 7.2988, 9.6607, 4.9063, 6.1282,\n",
      "        4.9983, 7.7203, 9.0336, 4.5370, 5.4079, 6.2342, 9.8640, 6.7726, 5.4014,\n",
      "        5.0035, 7.4931, 5.7415, 6.2510, 4.8952, 6.6670, 7.1906, 5.5804, 8.6455,\n",
      "        9.4027, 4.9990, 5.6603, 5.8131, 9.6508, 7.1487, 7.7817, 7.5572, 4.9307,\n",
      "        6.1279, 6.7557, 7.4026, 4.4933, 5.3435, 5.4012, 5.2907, 4.1979, 5.4684,\n",
      "        5.4574, 5.2182, 7.9492, 8.3524, 7.2697, 7.7817, 6.7849, 6.2265, 6.6500,\n",
      "        5.3078])\n"
     ]
    }
   ],
   "source": [
    "from utils.check import datamodule_check\n",
    "datamodule_check('rbf', 'a9a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}